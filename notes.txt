
websockets with event machine
http://lorefnon.me/2012/08/15/a-websocket-powered-tic-tac-toe-game-using-ruby-eventmachine--part-1.html




- we still have a problem that the model is being updated
	in a different thread...
	uggh.

ok basic event machine support for concurrency.

- what we need is to to log the address it comes from.  

----

Ok, it looks like we have some kind of thread contention - on the model structure. 

can we deal with this, by passing the socket back into a single threaded app processing queue? 
	- eg. we have a thread to handle connection opening. 

	and another to process and write? which should make everything sequential...
	we just have to push the message into the queue.

	alternatively we try and rewrite the socket code,  

	- but it's not very good from the pov, of the final socket write/stream - that it could block?

	- in a normal web app, it's the db that handles all the parallelism.
	alternatively we have to force 
-----

todo.

rather than @model << elt. Should we push the thing as an event . eg event_sink.event( ) ; 

	and then let some other writer handle it? 
	eg. to go to db storage or in memory db, rdf etc.
	
	eg. streams on streams model. it's a fold. 

	the metadata - style, name, etc - can also be pushed as attributes.

	we should definitately abstract the end result. so there's one
	aggregator for all derivative streams.

when there's an ingest error. we need to encode the url.
	so we can tell which exchange was the problem

also don't encode json fields as string - eg id is an integer
	content - is already json.

we can do this, by looking at the type of each field before outputting.



-------
# these controllers ought to be put in the constroller module namespace
# then we can refer to them Controller::Session 

ok, 

- Use the listen interface to get time-synchronous stream. and replicate locally
	from aws instance. 
	- Might be possible to do it entirely in sql. if we can connect to two dbs 

	- we need event_ro  event_wr  db roles

- should change the name model to stream. or eventstream_ model etc.

- we can replication of the db data extremely easily. just by copying the 
event stream.

rather than set interval - we can compute it automatically. 

we need control over the series. just have to declare unit. then we can show axis. 

$200 means miners receive $263million per year. Um where exactly is that suppose to come from?

The 3600 btc a day is a cost as well that you pay when the price drops.

https://bitcoinwisdom.com/markets/bitfinex/btcusd

--- 

bter has api

https://bter.com/api

http://data.bter.com/api/1/pairs

eg. 
http://data.bter.com/api/1/depth/btsx_btc

it would be really good to monitor these.



----
btx has public order book. it's traded in terms of btc. so losing value.

https://bitcoinaverage.com/markets#USD

t's possible to speculate on the exchange by holding, 
then transfer back to btc blockchain to pull out.

bter has very tight spread for cny / btc. 


----

Ok, we want to be able to change the number of ticks. 

Our new state (stream)  - considered as a left fold.


-----

We want. total value of orders, and for ask and spread. 
	and to chart this.


----

done redirect to https

done supports streaming.

---

done Lets aggregate the model, conn into services and then pass to all 
the message cracker stuff.

also get remote end - ip address for logging.  and port to determine if ssl

and try to do some session management.

and if not ssl - do a 302 right at the start of the chain.


done rather than use functions for the filter chain. make these methods of application class
and have the server delegate.

done then inject conn and model into the application class.
 

done and compute real bollinger bands.

done Be nice to get a view of ES events, errors etc - . 

---

done we don't need db stuff to be atomic, because the model
is purely in memory

	- but if we want to do some queries against the db. eg. 
	for reporting? 

----

done we need matcher, and post filter operations. 

	request
	req_headers	

	response
	res_headers

	body (stream)

then a matcher, and filter. 

Eg. if we have the request then we can add caching behavior.
we can also communicate between filters if we need - using
variables 



	Think we may want a combined structure - not just peeling
	off the request and dispatching it. 

	request
	response
	entity  

	Then we can have filters anywhere - to add/delete/modify headers .

	filters are like cross cutting concerns.


entity is everything except the response.

------

Think there might be an issue that we need two \r\n fields 

echo -e 'GET / HTTP/1.1\r\n\r\n' | nc localhost 2345 | less

------

We don't need the class, can just use a mash

irb(main):001:0> x = { :a => File.new( 'jquery.js') } 
=> {:a=>#<File:jquery.js>}
irb(main):002:0> x.a.read
NoMethodError: undefined method `a' for {:a=>#<File:jquery.js>}:Hash
        from (irb):2
        from /usr/bin/irb:12:in `<main>'
irb(main):003:0> x[:a].read

-----

ok, i think we want to run the migration.
	need a backup first

----

ok, now we want to start recording. 
which means we actually need a test db. separate from the one we're using for
real.

we probably also want to integrate the code - into this project? 
or keep the ends separate?

----

- 369 - 375 USD/BTC  entered 8.00pm   ( actually bought aud at horrible spread)
											ANX AUD spread is 422 - 438 = 16

- for btc we really need. to test ingestion with a test db. 


- need to get real-time update. by polling or something.
	- very basic - need to test whether new data, before
	doing larger query or updating.

- IMPORTANT compress data, when sending.

- IMPORTANT cache control over resources jquery and jflot etc.



	http://www.jqplot.com/  looks nice as well as flot.
		supports multiple y axis also - http://www.jqplot.com/tests/zooming.php

- think we should route the message cracking down into the controller / model class.
- means there's just a single point to handle.
	- then we don't have to separate out the routing...


	- event_processor( model)
	- controller( model)
	- router( controller) 

- we need dates. 


- in place of web-sockets - it would be very easy to poll, requesting
whether there was any more data in the last 10 secs.  and then doing
an update.

---
done ok - , we want to pull out the key parsing from webserver.

done and change the name.

then create a web_root dir to some html 

done - change name keys to message or similar

change the serve file - so it takes the request - and not all the
	rest of the keys.

ok. now we actually want to serve model data.
----

it's very close to being real time.

ok, it would be nice to have real-time display of date 


# require 'cgi'
  # require 'base64'
  # 
  # def decode_utf8_b64(string)
  #   URI.unescape(CGI::escape(Base64.decode64(string)))
  # end
  # 
  #    query = matches.captures[0]
  #query = URI.unescape( matches.captures[0] ) 
  #    query = decode_utf8_b64(  matches.captures[0]  )
  # ?field1=select+*+from+mytable+limit+1
  # what about handling + signs
  #query = query.gsub(/+/, ' ' ); 


